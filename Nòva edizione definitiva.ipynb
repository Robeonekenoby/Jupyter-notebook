{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time, csv\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://nova.ilsole24ore.com/source/data-journalism-infodata/\") # home page del sito di Nova, sezione articoli di datajournalism \n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "cookie = driver.find_element_by_xpath('//*[@id=\"onetrust-accept-btn-handler\"]').click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "altri_articoli = driver.find_element_by_id(\"load-link\")\n",
    "for i in range(2):    # 2 per prova ma metterlo su 200 per far uscire circa 2392 articoli ma essendo un sito un po' così può bloccarsi talvolta\n",
    "    time.sleep(2)\n",
    "    altri_articoli.click()\n",
    "    \n",
    "articoli = driver.find_elements_by_class_name(\"lead-normal\")\n",
    "#len(articoli)\n",
    "\n",
    "lista_articoli = []   # un array che conterrà i valori del dizionario art_item1\n",
    "solo_Link = []        # un array dove saranno inseriti esclusivamente i link degli articoli\n",
    "\n",
    "for articolo in articoli:\n",
    "    \n",
    "    link = articolo.find_element_by_xpath('.//*[@class=\"title\"]/h2/a').get_attribute('href')\n",
    "    titolo = articolo.find_element_by_xpath('.//*[@class=\"title\"]/h2/a').text # . (seleziona il nodo corrente) poichè senza si ripete il primo\n",
    "    categoria = articolo.find_element_by_xpath('.//*[@class=\"title\"]/h3/a').text\n",
    "     \n",
    "    data_pubblicazione = articolo.find_elements_by_tag_name(\"time\")\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for elemento in data_pubblicazione:\n",
    "        data.append(elemento.text)\n",
    "    \n",
    "\n",
    "\n",
    "    datina = ' '.join(map(str, data)) # Use map() method for mapping str (for converting elements in list to string) with given iterator, the list.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    now = datetime.now() # data nel formato Americano e orario corrente  #timestamp = ('Timestamp: %s' % datetime.datetime.now())\n",
    "    timestamp = now.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "    \n",
    "    art_item1 = {\n",
    "        'Link': link,\n",
    "        'Titolo': titolo,\n",
    "        'Categoria': categoria,\n",
    "        'Data_pubblicazione': datina, #data_pubblicazione singola non viene presa perchè prendiamo gli elementi time\n",
    "        'Timestamp dello scraping': timestamp\n",
    "    }\n",
    "    lista_articoli.append(art_item1)\n",
    "    solo_Link.append(link)\n",
    "\n",
    "driver.quit()    \n",
    "df1 = pd.DataFrame(lista_articoli)\n",
    "\n",
    "#df1.to_csv(r'C:\\Users\\robeo\\Desktop\\dataframeNova000.csv', index = False, header = True)\n",
    "\n",
    "#print(df1)\n",
    "#print(solo_Link)\n",
    "\n",
    "corpi = []\n",
    "\n",
    "for indirizzo in solo_Link:\n",
    "    driver = webdriver.Chrome()\n",
    "     \n",
    "    driver.get(indirizzo)      \n",
    "    \n",
    "    elementip = driver.find_elements_by_tag_name(\"p\") #lista intera di tutti gli elementi p\n",
    "\n",
    "    paragrafi = []\n",
    "    \n",
    "    for paragrafo in elementip:\n",
    "        paragrafi.append(paragrafo.text)\n",
    "    #print(paragrafi)\n",
    "\n",
    "\n",
    "    testo = ' '.join(map(str, paragrafi))   # Use map() method for mapping str (for converting elements in list to string) with given iterator, the list.\n",
    "\n",
    "\n",
    "    art_item2 = {\n",
    "        \n",
    "            'Testo': testo\n",
    "    }\n",
    "    \n",
    "    corpi.append(art_item2)\n",
    "\n",
    "    driver.quit()\n",
    "df2 = pd.DataFrame(corpi)\n",
    "\n",
    "dfTotale = pd.concat([df1,df2], axis = 1)\n",
    "dfTotale.to_csv(r'C:\\Users\\robeo\\Desktop\\dataframeNovaCompleto1.csv', index = True, header = True)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
