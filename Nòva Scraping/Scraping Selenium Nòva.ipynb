{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programma che effettua lo scraping agli articoli di datajournalism sul sito Nòva del Sole 24 Ore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, csv                 # sono importate le diverse librerie per il corretto funzionamento del bot\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()   # il driver è associato a Chrome \n",
    "\n",
    "driver.get(\"https://nova.ilsole24ore.com/source/data-journalism-infodata/\") # home page del sito di Nova, sezione articoli di datajournalism \n",
    "\n",
    "time.sleep(3) # il bot si addormenta per 3 secondi\n",
    "\n",
    "cookie = driver.find_element_by_xpath('//*[@id=\"onetrust-accept-btn-handler\"]').click() # viene cliccato il pulsante che accetta i cookie della pagina\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "altri_articoli = driver.find_element_by_id(\"load-link\")  # id del pulsante \"altri contenuti\"\n",
    "for i in range(200):    # 2 per prova ma metterlo su 200 per far uscire circa 2392 articoli ma essendo un sito un po' così può bloccarsi talvolta\n",
    "    time.sleep(2)\n",
    "    altri_articoli.click()\n",
    "    \n",
    "articoli = driver.find_elements_by_class_name(\"lead-normal\")  # classe degli articoli presenti nella pagina\n",
    "\n",
    "\n",
    "lista_articoli = []   # un array che conterrà i valori del dizionario art_item1\n",
    "solo_Link = []        # un array dove saranno inseriti esclusivamente i link degli articoli\n",
    "\n",
    "for articolo in articoli:\n",
    "    \n",
    "    link = articolo.find_element_by_xpath('.//*[@class=\"title\"]/h2/a').get_attribute('href')\n",
    "    titolo = articolo.find_element_by_xpath('.//*[@class=\"title\"]/h2/a').text # . (seleziona il nodo corrente) poichè senza si ripete il primo\n",
    "    categoria = articolo.find_element_by_xpath('.//*[@class=\"title\"]/h3/a').text\n",
    "     \n",
    "    data_pubblicazione = articolo.find_elements_by_tag_name(\"time\") \n",
    "    \n",
    "    lista_data = []   \n",
    "    \n",
    "    for elemento in data_pubblicazione:  # scorre gli elementi della lista data_pubblicazione \n",
    "        lista_data.append(elemento.text)       # prende il testo dell'elemento appendendolo all'array lista_data\n",
    "    \n",
    "\n",
    "\n",
    "    data = ' '.join(map(str, lista_data)) # map() prende in ingresso una o più liste e una funzione. Per ogni elemento presente in ciascuna lista specificata, viene applicata la funzione str() che lo converte in stringa.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    now = datetime.now() # data nel formato Americano e orario corrente\n",
    "    timestamp = now.strftime(\"%d/%m/%Y, %H:%M:%S\") # Il metodo strftime () restituisce una stringa che rappresenta la data e l'ora utilizzando l'oggetto date, time o datetime\n",
    "    \n",
    "    art_item1 = {        # primo dizionario che contiene per ogni articolo: link, titolo, categoria, datina( la data di pubblicazione), timestamp dello scraping\n",
    "        'Link': link,\n",
    "        'Titolo': titolo,\n",
    "        'Categoria': categoria,\n",
    "        'Data_pubblicazione': data, \n",
    "        'Timestamp dello scraping': timestamp\n",
    "    }\n",
    "    lista_articoli.append(art_item1)     # il primo dizionario è appeso a lista_articoli\n",
    "    solo_Link.append(link)               # ogni link è appeso all'array solo_Link\n",
    "\n",
    "driver.quit()                       # il bot si chiude\n",
    "df1 = pd.DataFrame(lista_articoli)  # tramite la libreria Pandas, la funzione DataFrame() trasforma la lista corpi in una tabella di oggetti eterogenei\n",
    "\n",
    "\n",
    "\n",
    "corpi = []                # array che conterrà i \"corpi\" degli articoli\n",
    "\n",
    "for indirizzo in solo_Link:    # scorre ogni link della lista solo_Link\n",
    "    driver = webdriver.Chrome()\n",
    "     \n",
    "    driver.get(indirizzo)      # il bot accede all'indirizzo\n",
    "    \n",
    "    elementip = driver.find_elements_by_tag_name(\"p\") #lista intera di tutti gli elementi p\n",
    "\n",
    "    paragrafi = []        # andrà a contenere l'insieme dei paragrafi che comporranno un singolo articolo\n",
    "    \n",
    "    for paragrafo in elementip:                # scorre gli elementi della lista elementip\n",
    "        paragrafi.append(paragrafo.text)       # prende il testo dell'elemento appendendolo all'array paragrafi\n",
    "        \n",
    "   \n",
    "    testo = ' '.join(map(str, paragrafi)) # map() prende in ingresso una o più liste e una funzione. Per ogni elemento presente in ciascuna lista specificata, viene applicata la funzione str() che lo converte in stringa.\n",
    "\n",
    "\n",
    "    art_item2 = {                         # secondo dizionario che contiene il testo di un singolo articolo\n",
    "        \n",
    "            'Testo': testo\n",
    "    }\n",
    "    \n",
    "    corpi.append(art_item2)  # il secondo dizionario è appeso alla lista corpi\n",
    "\n",
    "    driver.quit()            # il bot si arresta\n",
    "df2 = pd.DataFrame(corpi)    #tramite la libreria Pandas, la funzione DataFrame() trasforma la lista corpi in una tabella di oggetti eterogenei\n",
    "\n",
    "dfTotale = pd.concat([df1,df2], axis = 1) # i due dataframe sono concatenati in un unico dataframe\n",
    "dfTotale.to_csv(r'C:\\Users\\robeo\\Desktop\\dataframe_Nòva.csv', index = True, header = True) # il dataframe complessivo è convertito nel formato CSV\n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
